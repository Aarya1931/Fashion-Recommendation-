{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovbs3wRmD7vU",
        "outputId": "b4a21c23-d6bf-4270-8566-ec2b0add8b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.15)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.54)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.18.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.11.4)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\n",
            "Requirement already satisfied: torch<2.4,>=1.10 in /usr/local/lib/python3.10/dist-packages (from fastai) (2.3.1+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=1.10->fastai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.4,>=1.10->fastai) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBAD8-nyAyF4",
        "outputId": "b85e11b7-6de8-41d7-dff3-a6bab35402b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=552451 sha256=ceed13e32bd6acfa3a64c9a6e08fa633b7b98a3f8632cce9a0806ab33bbbedbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPosQNJE-hdn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import accuracy, top_k_accuracy\n",
        "from annoy import AnnoyIndex\n",
        "import zipfile\n",
        "import time\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the meta data\n",
        "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pWnFiNlNGTVloLUk'\n",
        "output = 'list_category_cloth.txt'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pTGNoWkhZeVpzbFk'\n",
        "output = 'list_category_img.txt'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pdS1FMlNreEwtc1E'\n",
        "output = 'list_eval_partition.txt'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "xNvVyq7T-lkE",
        "outputId": "4bb73148-35cc-4046-fe34-3a131d9c1c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pWnFiNlNGTVloLUk\n",
            "To: /content/list_category_cloth.txt\n",
            "100%|██████████| 882/882 [00:00<00:00, 2.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pTGNoWkhZeVpzbFk\n",
            "To: /content/list_category_img.txt\n",
            "100%|██████████| 21.4M/21.4M [00:00<00:00, 34.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pdS1FMlNreEwtc1E\n",
            "To: /content/list_eval_partition.txt\n",
            "100%|██████████| 22.2M/22.2M [00:00<00:00, 48.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'list_eval_partition.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the images\n",
        "root_path = './'\n",
        "url = 'https://drive.google.com/uc?id=1j5fCPgh0gnY6v7ChkWlgnnHH6unxuAbb'\n",
        "output = 'img.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "with zipfile.ZipFile(\"img.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(root_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWmxMiwQ-zK5",
        "outputId": "03c03b68-dd7d-4ff9-fc98-bdf0ea92b4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1j5fCPgh0gnY6v7ChkWlgnnHH6unxuAbb\n",
            "From (redirected): https://drive.google.com/uc?id=1j5fCPgh0gnY6v7ChkWlgnnHH6unxuAbb&confirm=t&uuid=9af9bbb3-f942-4bae-87d8-a70a040e3f30\n",
            "To: /content/img.zip\n",
            "100%|██████████| 2.68G/2.68G [01:23<00:00, 32.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_list = []\n",
        "image_path_list = []\n",
        "data_type_list = []\n",
        "# category names\n",
        "with open('list_category_cloth.txt', 'r') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        if i > 1:\n",
        "            category_list.append(line.split(' ')[0])\n",
        "\n",
        "# category map\n",
        "with open('list_category_img.txt', 'r') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        if i > 1:\n",
        "            image_path_list.append([word.strip() for word in line.split(' ') if len(word) > 0])\n",
        "\n",
        "\n",
        "# train, valid, test\n",
        "with open('list_eval_partition.txt', 'r') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        if i > 1:\n",
        "            data_type_list.append([word.strip() for word in line.split(' ') if len(word) > 0])\n",
        "\n",
        "data_df = pd.DataFrame(image_path_list, columns=['image_path', 'category_number'])\n",
        "data_df['category_number'] = data_df['category_number'].astype(int)\n",
        "data_df = data_df.merge(pd.DataFrame(data_type_list, columns=['image_path', 'dataset_type']), on='image_path')\n",
        "data_df['category'] = data_df['category_number'].apply(lambda x: category_list[int(x) - 1])\n",
        "data_df = data_df.drop('category_number', axis=1)\n"
      ],
      "metadata": {
        "id": "lp_t9SoI-8nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpfJJUljD-iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25hB1-FYD-_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_list = ImageList.from_df(df=data_df, path=root_path, cols='image_path').split_by_idxs(\n",
        "    (data_df[data_df['dataset_type']=='train'].index),\n",
        "    (data_df[data_df['dataset_type']=='val'].index)).label_from_df(cols='category')\n",
        "test_image_list = ImageList.from_df(df=data_df[data_df['dataset_type'] == 'test'], path=root_path, cols='image_path')\n",
        "\n",
        "data = train_image_list.transform(get_transforms(), size=224).databunch(bs=128).normalize(imagenet_stats)\n",
        "data.add_test(test_image_list)\n",
        "data.show_batch(rows=3, figsize=(8,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dFCfDo3U_FnX",
        "outputId": "33a5e749-b47c-455c-a029-8814db2310ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ImageList' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4183401e335>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_image_list = ImageList.from_df(df=data_df, path=root_path, cols='image_path').split_by_idxs(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     (data_df[data_df['dataset_type']=='val'].index)).label_from_df(cols='category')\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_image_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageList' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see models available: https://docs.fast.ai/vision.models.html\n",
        "# many options for Resnet, the numbers are the number of layers.\n",
        "# More layers are generally more accurate but take longer to train: resnet18, resnet34, resnet50, resnet101, resnet152\n",
        "# get top 1 and top 5 accuracy\n",
        "def train_model(data, pretrained_model, model_metrics):\n",
        "    learner = cnn_learner(data, pretrained_model, metrics=model_metrics)\n",
        "    learner.model = torch.nn.DataParallel(learner.model)\n",
        "    learner.lr_find()\n",
        "    learner.recorder.plot(suggestion=True)\n",
        "    return learner\n",
        "\n",
        "pretrained_model = models.resnet18 # simple model that can be trained on free tier\n",
        "# pretrained_model = models.resnet50 # need pro tier, model I used\n",
        "\n",
        "model_metrics = [accuracy, partial(top_k_accuracy, k=1), partial(top_k_accuracy, k=5)]\n",
        "learner = train_model(data, pretrained_model, model_metrics)\n",
        "learner.fit_one_cycle(10, max_lr=1e-02)"
      ],
      "metadata": {
        "id": "gzjOE_qS_JB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learner)\n",
        "interp.plot_top_losses(9, largest=False, figsize=(15,11), heatmap_thresh=5)"
      ],
      "metadata": {
        "id": "DPM_TwXI_KCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model (temporary, will lose model once environment resets)\n",
        "learner.save('resnet-fashion')"
      ],
      "metadata": {
        "id": "jo0jhWpR_PGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    features=None\n",
        "    def _init_(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_fn)\n",
        "        self.features = None\n",
        "    def hook_fn(self, module, input, output):\n",
        "        out = output.detach().cpu().numpy()\n",
        "        if isinstance(self.features, type(None)):\n",
        "            self.features = out\n",
        "        else:\n",
        "            self.features = np.row_stack((self.features, out))\n",
        "    def remove(self):\n",
        "        self.hook.remove()\n",
        "\n",
        "  # load the trained model\n",
        "def load_learner(data, pretrained_model, model_metrics, model_path):\n",
        "    learner = cnn_learner(data, pretrained_model, metrics=model_metrics)\n",
        "    learner.model = torch.nn.DataParallel(learner.model)\n",
        "    learner = learner.load(model_path)\n",
        "    return learner\n",
        "\n",
        "pretrained_model = models.resnet18 # simple model that can be trained on free tier\n",
        "# pretrained_model = models.resnet50 # need pro tier\n",
        "\n",
        "model_metrics = [accuracy, partial(top_k_accuracy, k=1), partial(top_k_accuracy, k=5)]\n",
        "# if gdrive not mounted:\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "model_path = \"/content/gdrive/My Drive/resnet18-fashion\"\n",
        "# model_path = \"/content/gdrive/My Drive/resnet50-fashion\"\n",
        "learner = load_learner(data, pretrained_model, model_metrics, model_path)"
      ],
      "metadata": {
        "id": "bvK9cHnN_PO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes time to populate the embeddings for each image\n",
        "# Get 2nd last layer of the model that stores the embedding for the image representations\n",
        "# the last linear layer is the output layer.\n",
        "saved_features = SaveFeatures(learner.model.module[1][4])\n",
        "_= learner.get_preds(data.train_ds)\n",
        "_= learner.get_preds(DatasetType.Valid)"
      ],
      "metadata": {
        "id": "boOpn5_c_PZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data for generating recommendations (exlcude test data)\n",
        "# get the embeddings from trained model\n",
        "img_path = [str(x) for x in (list(data.train_ds.items) +list(data.valid_ds.items))]\n",
        "label = [data.classes[x] for x in (list(data.train_ds.y.items) +list(data.valid_ds.y.items))]\n",
        "label_id = [x for x in (list(data.train_ds.y.items) +list(data.valid_ds.y.items))]\n",
        "data_df_ouput = pd.DataFrame({'img_path': img_path, 'label': label, 'label_id': label_id})\n",
        "data_df_ouput['embeddings'] = np.array(saved_features.features).tolist()\n",
        "# Using Spotify's Annoy\n",
        "def get_similar_images_annoy(annoy_tree, img_index, number_of_items=12):\n",
        "    start = time.time()\n",
        "    img_id, img_label  = data_df_ouput.iloc[img_index, [0, 1]]\n",
        "    similar_img_ids = annoy_tree.get_nns_by_item(img_index, number_of_items+1)\n",
        "    end = time.time()\n",
        "    print(f'{(end - start) * 1000} ms')\n",
        "    # ignore first item as it is always target image\n",
        "    return img_id, img_label, data_df_ouput.iloc[similar_img_ids[1:]]\n",
        "\n",
        "\n",
        "# for images similar to centroid\n",
        "def get_similar_images_annoy_centroid(annoy_tree, vector_value, number_of_items=12):\n",
        "    start = time.time()\n",
        "    similar_img_ids = annoy_tree.get_nns_by_vector(vector_value, number_of_items+1)\n",
        "    end = time.time()\n",
        "    print(f'{(end - start) * 1000} ms')\n",
        "    # ignore first item as it is always target image\n",
        "    return data_df_ouput.iloc[similar_img_ids[1:]]\n",
        "\n",
        "\n",
        "def show_similar_images(similar_images_df, fig_size=[10,10], hide_labels=True):\n",
        "    if hide_labels:\n",
        "        category_list = []\n",
        "        for i in range(len(similar_images_df)):\n",
        "            # replace category with blank so it wont show in display\n",
        "            category_list.append(CategoryList(similar_images_df['label_id'].values*0,\n",
        "                                              [''] * len(similar_images_df)).get(i))\n",
        "    else:\n",
        "        category_list = [learner.data.train_ds.y.reconstruct(y) for y in similar_images_df['label_id']]\n",
        "    return learner.data.show_xys([open_image(img_id) for img_id in similar_images_df['img_path']],\n",
        "                                category_list, figsize=fig_size)\n",
        "  # more tree = better approximation\n",
        "ntree = 100\n",
        "#\"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"\n",
        "metric_choice = 'angular'\n",
        "\n",
        "annoy_tree = AnnoyIndex(len(data_df_ouput['embeddings'][0]), metric=metric_choice)\n",
        "\n",
        "# # takes a while to build the tree\n",
        "for i, vector in enumerate(data_df_ouput['embeddings']):\n",
        "    annoy_tree.add_item(i, vector)\n",
        "_  = annoy_tree.build(ntree)"
      ],
      "metadata": {
        "id": "TUC0JYB5_PfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def centroid_embedding(outfit_embedding_list):\n",
        "    number_of_outfits = outfit_embedding_list.shape[0]\n",
        "    length_of_embedding = outfit_embedding_list.shape[1]\n",
        "    centroid = []\n",
        "    for i in range(length_of_embedding):\n",
        "        centroid.append(np.sum(outfit_embedding_list[:, i])/number_of_outfits)\n",
        "    return centroid\n",
        " # shorts\n",
        "outfit_img_ids = [109938, 106385, 113703, 98666, 113467, 120667, 20840, 8450, 142843, 238607, 124505,222671]\n",
        "outfit_embedding_list = []\n",
        "for img_index in outfit_img_ids:\n",
        "    outfit_embedding_list.append(data_df_ouput.iloc[img_index, 3])\n",
        "\n",
        "outfit_embedding_list = np.array(outfit_embedding_list)\n",
        "outfit_centroid_embedding = centroid_embedding(outfit_embedding_list)\n",
        "outfits_selected = data_df_ouput.iloc[outfit_img_ids]\n",
        "\n",
        "similar_images_df = get_similar_images_annoy_centroid(annoy_tree, outfit_centroid_embedding, 30)"
      ],
      "metadata": {
        "id": "AHS3Cwjj_PkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_similar_images(outfits_selected, fig_size=[15,15])"
      ],
      "metadata": {
        "id": "XJ9z_32z_eQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}